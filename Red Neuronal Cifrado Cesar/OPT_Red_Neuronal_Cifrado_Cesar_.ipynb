{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OPT Red Neuronal Cifrado Cesar .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn5-cW-2iIPD"
      },
      "source": [
        "# **RED NEURONAL CIFRADO CESAR. BÚSQUEDA DE PARÁMETROS ÓPTIMOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTn36TjoHzm5"
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import SimpleRNN, Input, Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import string\n",
        "import random\n",
        "\n",
        "# Parametros configuración inicial\n",
        "word_size = 3 # tamaño cadenas\n",
        "shift = 3 # Desplazamiento letra (cifrado)\n",
        "\n",
        "# Declaración de parámetros\n",
        "nn = [120,80,120,80,26*word_size]\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "# Generar el dataset de entrenamiento\n",
        "X, Y = generate_words(10000,0,X)\n",
        "X_train = wordToNumber(X)\n",
        "Y_train = wordToNumber(Y)\n",
        "\n",
        "# Generar el dataset de test (datos nuevos, no usados en el entrenamiento)\n",
        "X, Y = generate_words(2000,1,X)\n",
        "X_test = wordToNumber(X)\n",
        "Y_test = wordToNumber(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtzT1xEDjrv7"
      },
      "source": [
        "def crearModelo(loss='poisson',activation='relu', unit1=120, unit2=80,optimizer='RMSprop'):\n",
        "\n",
        "  # Definir modelo    \n",
        "  model = Sequential()\n",
        "\n",
        "  # Capas\n",
        "  model.add(Dense(nn[4], input_dim=(26*word_size)))\n",
        "  model.add(Dense(unit1, activation))\n",
        "  model.add(Dense(unit2, activation))\n",
        "  model.add(Dense(unit1, activation))\n",
        "  model.add(Dense(nn[4], activation))\n",
        "\n",
        "  # Compilar modelo\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VhyqoUWiOB_"
      },
      "source": [
        "batch_size = [200,300,500]\n",
        "epochs = [50, 100, 150]\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad','Adam', 'Adamax', 'Nadam']\n",
        "loss = ['binary_crossentropy','categorical_crossentropy','poisson']\n",
        "activation = ['softmax','relu','sigmoid','softplus']\n",
        "unit1 = [80,100,120]\n",
        "unit2 = [100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmZcMlwmCiDc"
      },
      "source": [
        "model = KerasClassifier(build_fn=crearModelo, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, unit1=unit1, unit2=unit2, loss=loss, activation=activation)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-A3BEQ3XfPf"
      },
      "source": [
        "def generate_words (number_words,test,X_train):\n",
        "  words = []\n",
        "\n",
        "  if(test == 0):\n",
        "    for x in range(number_words):\n",
        "      words.append(''.join(random.SystemRandom().choice(string.ascii_letters).lower() for _ in range(word_size)))\n",
        "  else:\n",
        "    for x in range(number_words):\n",
        "      repeated = 1\n",
        "      while(repeated == 1):\n",
        "        word = (''.join(random.SystemRandom().choice(string.ascii_letters).lower() for _ in range(word_size)))\n",
        "        if(word not in X_train):\n",
        "          words.append(word)\n",
        "          repeated = 0\n",
        "\n",
        "  encrypted_words = []\n",
        "\n",
        "  for word in words:\n",
        "    cadena = \"\"\n",
        "    for x in range(0,word_size):\n",
        "      cadena += chr((((ord(word[x]) - 97) + shift) % 26) + 97)\n",
        "    encrypted_words.append(cadena)\n",
        "\n",
        "  return encrypted_words, words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYajFQSpIGzJ"
      },
      "source": [
        "def wordToNumber(words):\n",
        "\n",
        "    word_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9,'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14,'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19,'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n",
        "    lista = []\n",
        "    x = 0\n",
        "    one_hot_encoding = np.zeros((len(words),len(word_id)*word_size))\n",
        "    for word in words:  \n",
        "      for i in range(0,word_size):\n",
        "        one_hot_encoding[x][word_id[word[i]]+(26*i)] = 1\n",
        "      x+=1\n",
        "    return one_hot_encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}